Metadata-Version: 2.4
Name: moodtrace-benchmark
Version: 0.1.0
Summary: MoodTrace Benchmark: longitudinal emotion dialogue dataset loader + evaluation scaffold.
Project-URL: Homepage, https://github.com/<YOUR_GITHUB>/moodtrace-benchmark
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: tqdm

# MoodTrace Benchmark (v0.1)

A longitudinal emotion dialogue benchmark scaffold:
- `load_dataset(name)` loads pair-level JSONL records
- `EmotionalEval(model).evaluate(ds)` runs a minimal stats-only evaluation (no LLM calls in v0.1)

## Quickstart

```python
from moodtrace_benchmark import load_dataset, EmotionalEval

ds = load_dataset("MoodTrace-20D", data_path="/path/to/all_clean.jsonl")
score = EmotionalEval("mock").evaluate(ds)
print(score)


